{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5, Option C, Step II: Post Process Simulation Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author's Workday ID: C175799, Initials: RPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018.05.09 14:10\n",
      "Time to process: [1.0] hours\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from haversine import haversine\n",
    "import math\n",
    "import random\n",
    "from multiprocessing import Process, current_process\n",
    "import hashlib\n",
    "import glob\n",
    "\n",
    "def get_time( output=True ):\n",
    "    \n",
    "    temp = time.time()\n",
    "    if output:\n",
    "        now = datetime.datetime.now()\n",
    "        print( now.strftime( \"%Y.%m.%d %H:%M\" ) )\n",
    "        \n",
    "    return temp\n",
    "\n",
    "foo = get_time()\n",
    "\n",
    "def print_time( start_time, end_time, interval=\"seconds\" ):\n",
    "    \n",
    "    if interval == \"hours\":\n",
    "        print ( \"Time to process: [%s] hours\" % ( str( ( end_time - start_time ) / 60 / 60 ) ) )\n",
    "    else:\n",
    "        print ( \"Time to process: [%s] seconds\" % ( str( end_time - start_time ) ) )\n",
    "\n",
    "print_time( 0, 3600, interval=\"hours\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate, Summarize and Write Hits Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits_files 10\n",
      "2018.05.09 14:10\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-32.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:10\n",
      "2018.05.09 14:10\n",
      "Time to process: [1.9337279796600342] seconds\n",
      "2018.05.09 14:10\n",
      "nearby_taxis_by_hash_grp 10051\n",
      "Queries w/ hits [10051] out of ~[16615] = [60.49]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1645353], mean taxis [163.70] per successful query\n",
      "2018.05.09 14:10\n",
      "Time to process: [0.25353336334228516] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-34.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:10\n",
      "2018.05.09 14:10\n",
      "Time to process: [1.889521837234497] seconds\n",
      "2018.05.09 14:10\n",
      "nearby_taxis_by_hash_grp 10968\n",
      "Queries w/ hits [10968] out of ~[16615] = [66.01]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1664653], mean taxis [151.77] per successful query\n",
      "2018.05.09 14:10\n",
      "Time to process: [0.2442188262939453] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-39.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:10\n",
      "2018.05.09 14:10\n",
      "Time to process: [2.171234607696533] seconds\n",
      "2018.05.09 14:10\n",
      "nearby_taxis_by_hash_grp 11416\n",
      "Queries w/ hits [11416] out of ~[16615] = [68.71]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1913908], mean taxis [167.65] per successful query\n",
      "2018.05.09 14:10\n",
      "Time to process: [0.2157728672027588] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-38.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:10\n",
      "2018.05.09 14:10\n",
      "Time to process: [1.5418758392333984] seconds\n",
      "2018.05.09 14:10\n",
      "nearby_taxis_by_hash_grp 10757\n",
      "Queries w/ hits [10757] out of ~[16615] = [64.74]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1364053], mean taxis [126.81] per successful query\n",
      "2018.05.09 14:10\n",
      "Time to process: [0.181260347366333] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-33.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:10\n",
      "2018.05.09 14:11\n",
      "Time to process: [2.4721784591674805] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 10836\n",
      "Queries w/ hits [10836] out of ~[16615] = [65.22]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [2149377], mean taxis [198.36] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.2849438190460205] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-36.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "2018.05.09 14:11\n",
      "Time to process: [1.2983806133270264] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 10624\n",
      "Queries w/ hits [10624] out of ~[16615] = [63.94]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1152644], mean taxis [108.49] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.12827444076538086] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-37.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "2018.05.09 14:11\n",
      "Time to process: [1.843409776687622] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 10579\n",
      "Queries w/ hits [10579] out of ~[16615] = [63.67]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1602958], mean taxis [151.52] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.22498583793640137] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-31.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "2018.05.09 14:11\n",
      "Time to process: [2.2159512042999268] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 9949\n",
      "Queries w/ hits [9949] out of ~[16615] = [59.88]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1913647], mean taxis [192.35] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.2801017761230469] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-35.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "2018.05.09 14:11\n",
      "Time to process: [1.5519139766693115] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 9653\n",
      "Queries w/ hits [9653] out of ~[16615] = [58.10]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1380560], mean taxis [143.02] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.17248964309692383] seconds\n",
      "==========================================================================================\n",
      "Loading HITS file [data/uber-simulation/points-process-40.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "2018.05.09 14:11\n",
      "Time to process: [1.8875133991241455] seconds\n",
      "2018.05.09 14:11\n",
      "nearby_taxis_by_hash_grp 10895\n",
      "Queries w/ hits [10895] out of ~[16615] = [65.57]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n",
      "Taxis nearby [1651959], mean taxis [151.63] per successful query\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.21638727188110352] seconds\n",
      "2018.05.09 14:11\n",
      "Time to process: [21.66267704963684] seconds\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob( \"data/uber-simulation/*.csv\" )\n",
    "\n",
    "hits_files = []\n",
    "misses_files = []\n",
    "\n",
    "for file in all_files:\n",
    "    \n",
    "    if ( file.find( \"points-process-\" ) > -1 ) and ( file.find( \"-error\" ) > 0 ):\n",
    "        misses_files.append( file )\n",
    "    elif file.find( \"points-process-\" ) > -1:\n",
    "        hits_files.append( file )\n",
    "    else:\n",
    "        print( \"Wuh?!?\" )\n",
    "        \n",
    "print( \"hits_files\", len( hits_files ) )\n",
    "#print( hits_files )\n",
    "        \n",
    "# setup for concatenation\n",
    "all_summaries = pd.DataFrame()\n",
    "all_summaries_list = []\n",
    "\n",
    "start_all_time = get_time()\n",
    "\n",
    "for file in hits_files:\n",
    "    \n",
    "    print( \"==========================================================================================\" )\n",
    "    print( \"Loading HITS file [%s]...\" % ( file ) )\n",
    "    print( \"==========================================================================================\" )\n",
    "    start_time = get_time()\n",
    "    one_tenth = pd.read_csv( file )\n",
    "    print_time( start_time, get_time() )\n",
    "    \n",
    "    start_time = get_time()\n",
    "    # turns out \"hash\" as a column name collides w/ reserved words :-|\n",
    "    one_tenth.rename( columns={ \"hash\":\"hashed_id\" }, inplace=True )\n",
    "    \n",
    "    agg_funcs = { \"hashed_id\":[ \"count\" ], \"total_mins\":[ \"min\", \"max\", \"mean\" ], \"delta\":[ \"min\", \"max\", \"mean\" ], \"my_lat\":[ \"mean\" ], \"my_lon\":[ \"mean\" ], \"my_bearing\":[ \"mean\" ] }\n",
    "    nearby_taxis_by_hash_grp = one_tenth.groupby( \"hashed_id\" ).agg( agg_funcs )\n",
    "    \n",
    "    # use ravel() to unite min, max, median w/ their parent column: \n",
    "    # https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "    nearby_taxis_by_hash_grp.columns = [ \"_\".join( col_name ) for col_name in nearby_taxis_by_hash_grp.columns.ravel() ]\n",
    "    \n",
    "    # finish flattening: https://intoli.com/blog/pandas-aggregation/\n",
    "    nearby_taxis_by_hash_grp.reset_index( inplace=True )\n",
    "    nearby_taxis_by_hash_grp.rename( columns={ \"hashed_id_count\":\"taxis_nearby\", \"my_lat_mean\":\"my_lat\", \"my_lon_mean\":\"my_lon\", \"my_bearing_mean\":\"my_bearing\" }, inplace=True)\n",
    "    nearby_taxis_by_hash_grp.sort_values( by=\"taxis_nearby\", ascending=False, inplace=True )\n",
    "    print( \"nearby_taxis_by_hash_grp\", len( nearby_taxis_by_hash_grp ) )\n",
    "    \n",
    "    lat_lon_bins = 989 * 7 * 24\n",
    "    cores = 10\n",
    "    hours_to_complete = 25 / 60\n",
    "\n",
    "    queries_per_core = lat_lon_bins / cores\n",
    "    successful_queries = len( nearby_taxis_by_hash_grp )\n",
    "    print( \"Queries w/ hits [%d] out of ~[%d] = [%.2f]%% hit rate\" % ( successful_queries, queries_per_core, successful_queries / queries_per_core * 100 ) )\n",
    "\n",
    "    # calculate queries per sec on one core\n",
    "    queries_per_sec = queries_per_core / hours_to_complete / 60 /60\n",
    "    print( \"Queries [%.2f] sec per core. Total queries ~[%.2f] sec on [%d] cores\" % ( queries_per_sec, queries_per_sec * cores, cores ) )\n",
    "\n",
    "    taxis_nearby = nearby_taxis_by_hash_grp.taxis_nearby.sum()\n",
    "    taxis_nearby_mean = nearby_taxis_by_hash_grp.taxis_nearby.mean()\n",
    "    print( \"Taxis nearby [%d], mean taxis [%.2f] per successful query\" % (  taxis_nearby, taxis_nearby_mean, ) )\n",
    "\n",
    "    all_summaries_list.append( nearby_taxis_by_hash_grp )\n",
    "    print_time( start_time, get_time() )\n",
    "\n",
    "    \n",
    "all_summaries = pd.concat( all_summaries_list )\n",
    "all_summaries.to_csv( \"data/taxis-nearby-hits-2.csv\", index=False )\n",
    "\n",
    "print_time( start_all_time, get_time() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate Misses Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018.05.09 14:11\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-38-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4759\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.0038557052612304688] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-39-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4266\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003268718719482422] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-32-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 5538\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003841876983642578] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-37-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4985\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.0035009384155273438] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-34-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4578\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.0032711029052734375] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-35-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 5742\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003969430923461914] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-40-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 5880\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.004334449768066406] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-33-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4795\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003520488739013672] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-31-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 5477\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003725767135620117] seconds\n",
      "==========================================================================================\n",
      "Loading MISSES file [data/uber-simulation/points-process-36-errors.csv]...\n",
      "==========================================================================================\n",
      "2018.05.09 14:11\n",
      "Rows 4836\n",
      "Index(['day', 'hour', 'lat_bin', 'lon_bin', 'bearing', 'lat', 'lon'], dtype='object')\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.003336191177368164] seconds\n",
      "2018.05.09 14:11\n",
      "Time to process: [0.23167800903320312] seconds\n"
     ]
    }
   ],
   "source": [
    "all_misses = pd.DataFrame()\n",
    "all_misses_list = []\n",
    "\n",
    "start_all_time = get_time()\n",
    "\n",
    "for file in misses_files:#[ 0:1 ]:\n",
    "    \n",
    "    print( \"==========================================================================================\" )\n",
    "    print( \"Loading MISSES file [%s]...\" % ( file ) )\n",
    "    print( \"==========================================================================================\" )\n",
    "    start_time = get_time()\n",
    "    misses = pd.read_csv( file, names=[ \"day\", \"hour\", \"lat_bin\", \"lon_bin\", \"bearing\", \"lat\", \"lon\" ] ) #, usecols=[ 0, 1, 2 ]\n",
    "    \n",
    "    print( \"Rows\", len( misses ) )\n",
    "    print( misses.columns )\n",
    "    all_misses_list.append( misses )\n",
    "    print_time( start_time, get_time() )\n",
    "\n",
    "all_misses = pd.concat( all_misses_list )\n",
    "all_misses.to_csv( \"data/taxis-nearby-misses-2.csv\", index=False )\n",
    "\n",
    "print_time( start_all_time, get_time() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105728\n",
      "50856\n",
      "166152\n",
      "Percent of hits [67.52]\n"
     ]
    }
   ],
   "source": [
    "print( len( all_summaries ) )\n",
    "print( len( all_misses ) )\n",
    "print( lat_lon_bins )\n",
    "print( \"Percent of hits [%.2f]\" % ( len( all_summaries ) / ( len( all_summaries ) + len( all_misses ) ) * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16439112"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_summaries.taxis_nearby.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries w/ hits [105728] out of ~[16615] = [636.33]% hit rate\n",
      "Queries [11.08] sec per core. Total queries ~[110.77] sec on [10] cores\n"
     ]
    }
   ],
   "source": [
    "lat_lon_bins = 989 * 7 * 24\n",
    "cores = 10\n",
    "hours_to_complete = 25 / 60\n",
    "\n",
    "queries_per_core = lat_lon_bins / cores\n",
    "successful_queries = len( all_summaries )\n",
    "print( \"Queries w/ hits [%d] out of ~[%d] = [%.2f]%% hit rate\" % ( successful_queries, queries_per_core, successful_queries / queries_per_core * 100 ) )\n",
    "\n",
    "# calculate queries per sec on one core\n",
    "queries_per_sec = queries_per_core / hours_to_complete / 60 /60\n",
    "print( \"Queries [%.2f] sec per core. Total queries ~[%.2f] sec on [%d] cores\" % ( queries_per_sec, queries_per_sec * cores, cores ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
